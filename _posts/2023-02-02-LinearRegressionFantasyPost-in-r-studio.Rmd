---
title: "Linear Regression to help Fanasty Football Drafting"
description: |
  Exploring the relationship between certain stats and PFF grades for receiving
author:
  - name: Michael Drewery
base_url: https://www.michaeldreweryanalytics.com/
date: 2023-02-02
preview: building.png
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

The beginning of my master’s program curriculum introduced linear regression as the introduction to model building. In practice, we were learning how to build this out in R, so it was exciting to progress in a new skill I came into the program looking to learn. This process timed well with the annual Fantasy Football Draft frenzy in August/September before the season begins. I’ve been playing for almost ten years now and was excited to apply some analytical skills to one of my many sports hobbies.

I understood my limitations with the predictions from a linear regression, and quite frankly didn’t see the value in generating an ordered list of projected points for players, as that never seemed to help with decision making in years past. “What if a few of your target players get drafted, how do re-prioritize remaining players?” was the question in the back of my mind. So from my perspective, there was more value in identifying key relationships in certain stats to fantasy point output, so I could have a fluid evaluation tool throughout the entire Fantasy Draft. I was specifically interested in identifying key metrics to compare between wide receivers as this position group is obviously the largest amount of players to choose from out of all position groups, and they usually take up the most roster spots per team.

The data utilized was a graded receiving summary from PFF for the years 2014-2019 which has a mix of raw statistics from the respective year and the company’s graded data assessing performance (0-100), every play, that’s aggregated to the game or season level. The next step was everyone’s favorite part, but definitely most crucial, and that was data cleaning. Teams’ locations change, players change names, and there are even players with the same name so all needs to be accounted for before moving on from exploratory data analysis. 


See the cleaned dataframe summary below that includes RBs, WRs, TEs:

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

#Reading in Data
wr_2014 <- read.csv("receiving_summary (5).csv")
wr_2015 <- read.csv("receiving_summary (4).csv")
wr_2016 <- read.csv("receiving_summary (3).csv")
wr_2017 <- read.csv("receiving_summary (2).csv")
wr_2018 <- read.csv("receiving_summary (1).csv")
wr_2019 <- read.csv("receiving_summary.csv")

#str(wr_2014)

library(tidyverse)
library(sqldf)

ovr_wr_summary <- bind_rows(wr_2014,wr_2015,wr_2016,wr_2017,wr_2018,wr_2019)

#Joining Draft data
draft_picks <- read_csv("https://raw.githubusercontent.com/leesharpe/nfldata/master/data/draft_picks.csv")

draft_picks_2000_onward <- draft_picks %>% filter(season >= 2000)

#Data manipulation below
ovr_wr_summary$player<-ovr_wr_summary$player%>%
  str_replace_all(c("yI "="y", "Jr."="", "Melvin Gordon I" = "Melvin Gordon","II"="","III"="", "IV"="", " V"="", "Sr."="", "nI "="n"))

ovr_wr_summary$player <- str_trim(ovr_wr_summary$player, "right")

str(ovr_wr_summary)
```




After my data manipulation step, I wanted to filter down on players in the data with more than 15 targets. From there I created my target variable “Fantasy_WR_Total”:

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

#Building out fantasy points below

nfl_data <- read.csv("mydata_filtered.csv")

nfl_data_final <- sqldf("select * from nfl_data where targets > 15")

view(nfl_data_final)

write.csv(nfl_data_final, "workingnfldataset.csv")

nfl_data_final_mutate <- mutate(nfl_data_final, Fantasy_WR_Yards=yards/10)

nfl_data_final_mutate <- mutate(nfl_data_final_mutate, Fantasy_WR_TDs=touchdowns*6)

nfl_data_final_mutate <- mutate(nfl_data_final_mutate, Fantasy_WR_Rec=receptions*.5)

nfl_data_final_mutate <- mutate(nfl_data_final_mutate, Fantasy_WR_Total=Fantasy_WR_Yards+Fantasy_WR_TDs+Fantasy_WR_Rec)

str(nfl_data_final_mutate)
```




I was curious how the offensive line performance impacted wide receiver fantasy production so I added PFF’s pass blocking efficiency grade to the data as another variable:

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

#Bringing in oline data

ol_2014 <- read.csv("line_pass_blocking_efficiency (5).csv")
ol_2015 <- read.csv("line_pass_blocking_efficiency (4).csv")
ol_2016 <- read.csv("line_pass_blocking_efficiency (3).csv")
ol_2017 <- read.csv("line_pass_blocking_efficiency (2).csv")
ol_2018 <- read.csv("line_pass_blocking_efficiency (1).csv")
ol_2019 <- read.csv("line_pass_blocking_efficiency.csv")

ovr_blocking_team_summary <- bind_rows(ol_2014,ol_2015,ol_2016,ol_2017,ol_2018,ol_2019)

joined_wr_ol <- nfl_data_final_mutate %>%
  left_join(ovr_blocking_team_summary, by = c("team_name" = "team_name", "year" = "year"), keep = TRUE)

view(joined_wr_ol)

write.csv(joined_wr_ol, "WR&OLdata.csv")

str(joined_wr_ol)

```




Keeping just player ID and year with all the other numeric and graded fields, I was ready to test assumptions before model building. I’ll highlight the order of assumption testing below:

1. Dataframe used for modeling
2. VIF (Variance Inflation Factor) for multicollinearity
3. Residual plot followed by Spearman's Test for Heteroscedascticity
4. Histogram of residuals followed by Anderson-Darling's normality test
5. Other residual plots to assess normality

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

nfl_model_data <- read.csv("WR&OLdata_filteredformodel.csv")

view(nfl_model_data)


library(AmesHousing)
library(tidyverse)
library(car)
library(DescTools)
library(corrplot)
library(mosaic)
library(modelr)
library(plotly)
library(ggplot2)
library(Hmisc)
library(onehot)
library(jmuOutlier)
library(leaps)
library(glmnet)
library(nortest)
library(lmtest)
library(InformationValue)
library(gmodels)
library(vcdExtra)
library(TSA)
library(carData)
library(epiDisplay)
library(gridExtra)
library(AppliedPredictiveModeling)

#lm.model=lm(Fantasy_WR_Total~.,data=nfl_model_data)
#vif(lm.model)



nfl_model_data_V2 <- read.csv("WR&OLdata_filteredformodel.csv")
str(nfl_model_data_V2)

lm.modelv2=lm(Fantasy_WR_Total~.,data=nfl_model_data_V2)
vif(lm.modelv2)


ggplot(lm.modelv2,aes(x=fitted(lm.modelv2),y=resid(lm.modelv2)))+geom_point(color="blue")+labs(x="Predicted Values",y="Residuals")

cor.test(abs(resid(lm.modelv2)),fitted.values(lm.modelv2),method="spearman",exact=T)

hist(resid(lm.modelv2))

ad.test(resid(lm.modelv2))

par(mfrow=c(2,2))
plot(lm.modelv2)
```




Once I confirmed the assumptions above, I moved onto examining the correlation matrix with my target variable:

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

nfl_model_data_V2 <- read.csv("WR&OLdata_filteredformodel.csv")

cor(nfl_model_data_V2[, c('Fantasy_WR_Total','targets','caught_percent','grades_offense','pbe','grades_pass_route', 'grades_hands_drop', 'yards_per_reception', 'yards_after_catch_per_reception', 'first_downs', 'avoided_tackles', 'targeted_qb_rating', 'touchdowns')])

```




After paying attention to the first column in our output above to get an idea of the strength of our relationship between our predictors and target. Now all that's left is reviewing our final model below:

```{r}
setwd("C:/Users/Michael/Documents/NC State/Side Project/NFL Combined Datasets WRs")

nfl_model_data_V2 <- read.csv("WR&OLdata_filteredformodel.csv")

lm.modelv2=lm(Fantasy_WR_Total~.,data=nfl_model_data_V2)

summary(lm.modelv2)
```




##Main Takeaway

1. First downs caught has the strongest relationship and largest impact on fantasy points
2. Targets should be prioritized regardless of offensive line pass blocking performance and QB
3. Touchdowns are obviously important but volatile year to year for players which must be considered

This translates to targeting WRs and TEs that are vertical threats who are trusted to move the chains for their teams. It also highlights leaning into the risky rookie class based on sheer volume in certain offenses. For me, this led to comparing first down catches from the year prior and average target depth, helpful in rookie cases, for almost every round I drafted a WR or TE.


##Results

1st (10 teams), 2nd (12 teams), 2nd (12 teams) in Points For (points scored by my team throughout weeks 1-14) across three leagues.

The research above led to some very positive outcomes for the season. I had high success targeting these types of WRs and TEs such as: DeVonta Smith, Chris Olave, Garrett Wilson, Christian Watson, David Njoku, Cole Kmet, Michael Pittman Jr., Drake London. This pushed me to prioritize workhorse RBs in the beginning of the draft who also got receiving targets since the leagues are PPR scoring (Points Per Reception).

Below are the resources I also used to help draft my team. The first link removed some initial biases I had and allowed me to test it out myself in Python! The second link helped me pick the right combination of RBs for my teams by reviewing the plots of Rushing Yards Over Expected charted with EPA. This made me prioritize the likes of Nick Chubb and Aaron Jones in rounds 2 & 3 and Tony Pollard by round 6 in every league I could. It was also helpful to view QBs on the plot and really highlighted Josh Allen's rushing value. Wish we could see Cam Newton's to compare.

Correlation Matrices and Stacking Players - https://www.fantasyfootballdatapros.com/blog/intermediate/2
Rushing Yards Over Expected charted with EPA  - https://mfbanalytics.shinyapps.io/RYOE/

Thanks for checking out the post!


